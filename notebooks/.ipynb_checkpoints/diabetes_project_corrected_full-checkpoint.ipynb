{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a65a91",
   "metadata": {},
   "source": [
    "\n",
    "# Diabetes Prediction Project – Corrected, Interview-Ready Notebook\n",
    "\n",
    "This notebook walks through:\n",
    "\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Visualizations and plots\n",
    "- Data cleaning and preprocessing\n",
    "- Feature engineering\n",
    "- Training and evaluating multiple ML models\n",
    "- Hyperparameter tuning\n",
    "- Probability calibration\n",
    "- Exporting a final model and scaler for deployment (e.g., Streamlit app)\n",
    "\n",
    "The goal is **not just accuracy**, but to clearly show the **thinking process** for interviewers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744c1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports and setup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "sns.set()\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd5ca62",
   "metadata": {},
   "source": [
    "## 1. Load and inspect the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/diabetes.csv\")\n",
    "\n",
    "# Quick look\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b972275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Info and summary statistics\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a097ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e9f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shape (rows, columns)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7294b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of the target variable\n",
    "df['Outcome'].value_counts() * 100 / len(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1de416",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA) and Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a2ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Age distribution\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.xlabel(\"Age\", fontsize=10)\n",
    "plt.ylabel(\"Count\", fontsize=10)\n",
    "df[\"Age\"].hist(edgecolor=\"black\")\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d69e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Age\"].min(), df[\"Age\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ba4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Density plots for numeric features\n",
    "fig, ax = plt.subplots(4, 2, figsize=(20, 20))\n",
    "\n",
    "sns.distplot(df.Pregnancies, bins=20, ax=ax[0,0], color=\"red\")\n",
    "ax[0,0].set_title(\"Pregnancies\")\n",
    "\n",
    "sns.distplot(df.Glucose, bins=20, ax=ax[0,1], color=\"red\")\n",
    "ax[0,1].set_title(\"Glucose\")\n",
    "\n",
    "sns.distplot(df.BloodPressure, bins=20, ax=ax[1,0], color=\"red\")\n",
    "ax[1,0].set_title(\"Blood Pressure\")\n",
    "\n",
    "sns.distplot(df.SkinThickness, bins=20, ax=ax[1,1], color=\"red\")\n",
    "ax[1,1].set_title(\"Skin Thickness\")\n",
    "\n",
    "sns.distplot(df.Insulin, bins=20, ax=ax[2,0], color=\"red\")\n",
    "ax[2,0].set_title(\"Insulin\")\n",
    "\n",
    "sns.distplot(df.BMI, bins=20, ax=ax[2,1], color=\"red\")\n",
    "ax[2,1].set_title(\"BMI\")\n",
    "\n",
    "sns.distplot(df.DiabetesPedigreeFunction, bins=20, ax=ax[3,0], color=\"red\")\n",
    "ax[3,0].set_title(\"Diabetes Pedigree Function\")\n",
    "\n",
    "sns.distplot(df.Age, bins=20, ax=ax[3,1], color=\"red\")\n",
    "ax[3,1].set_title(\"Age\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d44dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mean feature values grouped by Outcome (0 = no diabetes, 1 = diabetes)\n",
    "df.groupby(\"Outcome\").agg({\n",
    "    'Pregnancies':'mean',\n",
    "    'Glucose':'mean',\n",
    "    'BloodPressure':'mean',\n",
    "    'SkinThickness':'mean',\n",
    "    'Insulin':'mean',\n",
    "    'BMI':'mean',\n",
    "    'DiabetesPedigreeFunction':'mean',\n",
    "    'Age':'mean'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b171e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outcome distribution: pie chart & countplot\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "df['Outcome'].value_counts().plot.pie(\n",
    "    explode=[0, 0.1],\n",
    "    autopct=\"%1.1f%%\",\n",
    "    shadow=True,\n",
    "    ax=ax[0]\n",
    ")\n",
    "ax[0].set_title(\"Outcome (Pie Chart)\")\n",
    "ax[0].set_ylabel(\"\")\n",
    "\n",
    "sns.countplot(x=\"Outcome\", data=df, ax=ax[1])\n",
    "ax[1].set_title(\"Outcome (Countplot)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d306bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation matrix\n",
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation heatmap\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"magma\", ax=ax)\n",
    "ax.set_title(\"Correlation Matrix\", fontsize=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d83ce7",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning: Replace Zeros, Impute Missing, Handle Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ca36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treat zeros as missing values for selected columns\n",
    "zero_as_na_cols = [\n",
    "    \"Pregnancies\",\n",
    "    \"Glucose\",\n",
    "    \"BloodPressure\",\n",
    "    \"SkinThickness\",\n",
    "    \"Insulin\",\n",
    "    \"BMI\",\n",
    "    \"DiabetesPedigreeFunction\",\n",
    "    \"Age\",\n",
    "]\n",
    "\n",
    "df[zero_as_na_cols] = df[zero_as_na_cols].replace(0, np.nan)\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0fd672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to compute median per Outcome\n",
    "def median_target(var):\n",
    "    temp = df[df[var].notnull()]\n",
    "    temp = temp[[var, \"Outcome\"]].groupby(\"Outcome\")[[var]].median().reset_index()\n",
    "    return temp\n",
    "\n",
    "# Median imputation by Outcome\n",
    "columns = df.columns.drop(\"Outcome\")\n",
    "for col in columns:\n",
    "    med = median_target(col)\n",
    "    df.loc[(df[\"Outcome\"] == 0) & (df[col].isnull()), col] = med[col][0]\n",
    "    df.loc[(df[\"Outcome\"] == 1) & (df[col].isnull()), col] = med[col][1]\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6782487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe368e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pairplot to visually inspect relationships between features and Outcome\n",
    "sns.pairplot(df, hue=\"Outcome\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14493ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Outlier detection with IQR rule (just to flag which features have potential outliers)\n",
    "for feature in df.columns:\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    if df[(df[feature] > upper)].any(axis=None):\n",
    "        print(feature, \"has potential high-end outliers\")\n",
    "    else:\n",
    "        print(feature, \"no major high-end outliers flagged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b0c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Boxplot for Insulin before capping\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.boxplot(x=df[\"Insulin\"], color=\"red\")\n",
    "plt.title(\"Insulin Before Capping\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cap Insulin using IQR rule\n",
    "Q1 = df[\"Insulin\"].quantile(0.25)\n",
    "Q3 = df[\"Insulin\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df.loc[df[\"Insulin\"] > upper, \"Insulin\"] = upper\n",
    "\n",
    "# Boxplot for Insulin after capping\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.boxplot(x=df[\"Insulin\"], color=\"red\")\n",
    "plt.title(\"Insulin After Capping\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Boxplot for Pregnancies to inspect distribution\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.boxplot(x=df[\"Pregnancies\"], color=\"red\")\n",
    "plt.title(\"Pregnancies Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove global outliers using Local Outlier Factor (LOF) on features only (exclude Outcome)\n",
    "lof = LocalOutlierFactor(n_neighbors=10)\n",
    "lof_scores = lof.fit_predict(df.drop(columns=[\"Outcome\"]))\n",
    "\n",
    "# -1 = outlier, 1 = inlier\n",
    "mask_inliers = lof_scores == 1\n",
    "df = df[mask_inliers].reset_index(drop=True)\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a092d",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering: BMI, Insulin Score, Glucose Categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe61958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BMI categories using standard WHO-ish cutoffs\n",
    "df[\"NewBMI\"] = pd.cut(\n",
    "    df[\"BMI\"],\n",
    "    bins=[0, 18.5, 24.9, 29.9, 34.9, 39.9, np.inf],\n",
    "    labels=[\n",
    "        \"Underweight\",\n",
    "        \"Normal\",\n",
    "        \"Overweight\",\n",
    "        \"Obesity 1\",\n",
    "        \"Obesity 2\",\n",
    "        \"Obesity 3\",\n",
    "    ],\n",
    ")\n",
    "df[\"NewBMI\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae149b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insulin score: Normal vs Abnormal\n",
    "def set_insulin(row):\n",
    "    if 16 <= row[\"Insulin\"] <= 166:\n",
    "        return \"Normal\"\n",
    "    else:\n",
    "        return \"Abnormal\"\n",
    "\n",
    "df[\"NewInsulinScore\"] = df.apply(set_insulin, axis=1)\n",
    "df[\"NewInsulinScore\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dce36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Glucose categories with meaningful medical cutoffs\n",
    "# - Low:        <= 70\n",
    "# - Normal:      71–99\n",
    "# - Prediabetic: 100–125\n",
    "# - High:       >= 126\n",
    "df[\"NewGlucose\"] = pd.cut(\n",
    "    df[\"Glucose\"],\n",
    "    bins=[0, 70, 99, 125, np.inf],\n",
    "    labels=[\"Low\", \"Normal\", \"Prediabetic\", \"High\"],\n",
    ")\n",
    "df[\"NewGlucose\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103151b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed86393",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One-hot encode engineered categorical features\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"NewBMI\", \"NewInsulinScore\", \"NewGlucose\"],\n",
    "    drop_first=True,\n",
    "    dtype=int,\n",
    ")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824fd97b",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split and Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target\n",
    "y = df[\"Outcome\"]\n",
    "X = df.drop(columns=[\"Outcome\"])\n",
    "\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Train/test split with stratification on Outcome\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0, stratify=y\n",
    ")\n",
    "\n",
    "# Standard scaling (note: this scaler will be saved for deployment)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b761c2",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "log_reg_acc = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "print(\"Logistic Regression Accuracy (test):\", log_reg_acc)\n",
    "print(confusion_matrix(y_test, y_pred_log))\n",
    "print(classification_report(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4974df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN Accuracy (test):\", knn_acc)\n",
    "print(confusion_matrix(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Support Vector Machine (SVM) with GridSearchCV\n",
    "svc = SVC(probability=True)\n",
    "\n",
    "svc_param_grid = {\n",
    "    \"gamma\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"C\": [0.01, 0.05, 0.5, 1, 10, 15, 20, 50, 100],\n",
    "    \"kernel\": [\"rbf\", \"linear\"],\n",
    "}\n",
    "\n",
    "grid_search_svc = GridSearchCV(svc, svc_param_grid, cv=5, n_jobs=-1)\n",
    "grid_search_svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVC Params:\", grid_search_svc.best_params_)\n",
    "print(\"Best CV Score (SVC):\", grid_search_svc.best_score_)\n",
    "\n",
    "svc_best = grid_search_svc.best_estimator_\n",
    "y_pred_svc = svc_best.predict(X_test)\n",
    "svc_acc = accuracy_score(y_test, y_pred_svc)\n",
    "\n",
    "print(\"SVC Accuracy (test):\", svc_acc)\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "print(classification_report(y_test, y_pred_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Decision Tree Classifier + GridSearchCV\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt_param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 10],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "    \"min_samples_leaf\": [1, 2, 3, 5, 7],\n",
    "    \"min_samples_split\": [2, 3, 5, 7],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "}\n",
    "\n",
    "grid_search_dt = GridSearchCV(dt, dt_param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best DT Params:\", grid_search_dt.best_params_)\n",
    "print(\"Best CV Score (DT):\", grid_search_dt.best_score_)\n",
    "\n",
    "dt_best = grid_search_dt.best_estimator_\n",
    "y_pred_dt = dt_best.predict(X_test)\n",
    "dt_acc = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Accuracy (test):\", dt_acc)\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b91df39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    min_samples_leaf=3,\n",
    "    min_samples_split=5,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest Accuracy (test):\", rf_acc)\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# XGBoost Classifier with RandomizedSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.4],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1, 1],\n",
    "    \"reg_lambda\": [1, 1.5, 2, 3],\n",
    "}\n",
    "\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost Params:\", random_search_xgb.best_params_)\n",
    "print(\"Best CV Score (XGBoost):\", random_search_xgb.best_score_)\n",
    "\n",
    "xgb_best = random_search_xgb.best_estimator_\n",
    "\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Accuracy (test):\", xgb_acc)\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17639b5c",
   "metadata": {},
   "source": [
    "## 7. Probability Calibration (for Better Probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0105b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calibrate the best XGBoost model using isotonic regression\n",
    "calibrated_model = CalibratedClassifierCV(\n",
    "    estimator=xgb_best,\n",
    "    cv=5,\n",
    "    method=\"isotonic\",\n",
    ")\n",
    "\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cal = calibrated_model.predict(X_test)\n",
    "cal_acc = accuracy_score(y_test, y_pred_cal)\n",
    "\n",
    "print(\"Calibrated XGBoost Accuracy (test):\", cal_acc)\n",
    "print(confusion_matrix(y_test, y_pred_cal))\n",
    "print(classification_report(y_test, y_pred_cal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae4efb",
   "metadata": {},
   "source": [
    "## 8. Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335523d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compare models in a DataFrame\n",
    "models_df = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"KNN\",\n",
    "        \"SVC (Best GridSearch)\",\n",
    "        \"Decision Tree (Best GridSearch)\",\n",
    "        \"Random Forest\",\n",
    "        \"XGBoost (Best)\",\n",
    "        \"Calibrated XGBoost\",\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        log_reg_acc,\n",
    "        knn_acc,\n",
    "        svc_acc,\n",
    "        dt_acc,\n",
    "        rf_acc,\n",
    "        xgb_acc,\n",
    "        cal_acc,\n",
    "    ],\n",
    "})\n",
    "\n",
    "models_df.sort_values(by=\"Accuracy\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa72be",
   "metadata": {},
   "source": [
    "## 9. Save Final Scaler and Model for Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be825f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the StandardScaler and calibrated XGBoost model\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "joblib.dump(calibrated_model, \"../models/model.pkl\")\n",
    "\n",
    "print(\"Scaler and calibrated model saved to ../models/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Diabetes ML Env",
   "language": "python",
   "name": "diabetes-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
